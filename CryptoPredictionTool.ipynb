{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Statements\n",
    "---\n",
    "**Important note:**\n",
    "For some reason tensorflow version and numpy version have dependency conflicts. Need to figure out what version is stable for both of these to work together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd                 # Pandas dataframe library\n",
    "import pandas_datareader as pdr     # Pandas datareader that allows me to lookup & store live crypto prices from yahoo finance.\n",
    "import numpy as np                  # Numpy\n",
    "import matplotlib.pyplot as pypl    # Pyplot used to create visuals/graphics based on data \n",
    "from alpha_vantage.timeseries import TimeSeries     # Library used for pulling live price data from alphavantage api\n",
    "\n",
    "from datetime import datetime, timedelta, timezone             # Datetime library.\n",
    "import pytz\n",
    "import json\n",
    "import csv\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=ResourceWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import glob                         # For changing/finding proper directory\n",
    "import os                           # For changing/finding proper directory (when opening files)\n",
    "import requests\n",
    "import twint                        # Twitter web scraping tool with more features than the regular twitter API\n",
    "import nest_asyncio                 # Import required for twint usage.\n",
    "nest_asyncio.apply()                \n",
    "\n",
    "import re                           # Regex for string cleaning (used for Textblob Sentiment Analysis)\n",
    "from textblob import TextBlob       # Textblob used for sentiment analysis of cleaned data.\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer    # Sentiment analysis tool that works great on determining social media sentiment.\n",
    "from newsapi import NewsApiClient   # NewsApiClient lets me look up/pull news articles relating to specified topics.\n",
    "import requests                     # Used for sending get requests to the NewsAPI client.\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler                          # Scaler used for scaling data (LSTMRNN Implementation)\n",
    "from sklearn.metrics import accuracy_score, classification_report       \n",
    "from sklearn.model_selection import train_test_split                    # Used for splitting data\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis    # Used for implementing SVM\n",
    "import tensorflow as tf                                                 # TF used for LSTMRNN Implmentation\n",
    "from keras.layers import Dense, Dropout, LSTM                           # Dense, dropout & lstm used for creating LSTMRNN \n",
    "from keras.models import Sequential                                     # Important because we're working with Sequential data.\n",
    "\n",
    "os.chdir(r'C:\\Users\\Brand\\OneDrive\\Documents\\GitHub\\CryptoPredictionTool\\archive')\n",
    "stopwords_file = open(\"stopwords.txt\", \"r+\")\n",
    "stopwords = list(stopwords_file.read().split('\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in crypto price dataset\n",
    "---\n",
    "Section below reads csv files into pandas dataframes for interacting with. Also compiles list of coin names for twitter searching.\n",
    "\n",
    "### What to do next:\n",
    "* Retrieve Token labels from CSV file for searching by Cashtag on twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'c:\\Users\\Brand\\OneDrive\\Documents\\GitHub\\CryptoPredictionTool\\prices\\DailyPrices'\n",
    "extension = 'csv'\n",
    "os.chdir(path)\n",
    "daily_csv_files = glob.glob('*.{}'.format(extension))\n",
    "\n",
    "\n",
    "path = r'c:\\Users\\Brand\\OneDrive\\Documents\\GitHub\\CryptoPredictionTool\\prices\\HourlyPrices'\n",
    "os.chdir(path)\n",
    "hourly_csv_files = glob.glob('*.{}'.format(extension))\n",
    "\n",
    "# Compile list of all coin names for searching on twitter later\n",
    "daily_coins = []\n",
    "hourly_coins = []\n",
    "\n",
    "for coin in daily_csv_files:\n",
    "    vals = coin.split(\"_\")\n",
    "    coin_name = vals[1][:-4]\n",
    "    daily_coins.append(coin_name)\n",
    "\n",
    "for coin in hourly_csv_files:\n",
    "    vals = coin.split(\"_\")\n",
    "    coin_name = vals[0]\n",
    "    hourly_coins.append(coin_name)\n",
    "\n",
    "# compile list of pandas dataframes for use later.\n",
    "hourly_coin_data = []\n",
    "\n",
    "for file in hourly_csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    hourly_coin_data.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hourly_coin_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE:* The cell below is for reading in the Bitcoin tweets dataset from Kaggle. (https://www.kaggle.com/datasets/kaushiksuresh147/bitcoin-tweets)\n",
    "This datset kinda sucks though. For a few reasons:\n",
    "* Firstly, its tweets span 1.5 years but are only from 43 total days, making it inconsistent to use with Sequential data, like the price history.\n",
    "* Secondly, it has some values in impropere columns (namely tag values in the date column) which have to be manually removed.\n",
    "* Lastly, its huge. 280k tweets. Which at first seems great, but being that the sample size itself is incredibly sparse in terms of date-span, this leads to problems with implementation. \n",
    "\n",
    "I'll leave it here in a cell in case I decide to use it later, but for now, it doesn't apply to this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!! BELOW IS THE LOGIC FOR READING IN THE TWEETS FROM THE BITCOIN TWEET KAGGLE DATASET !!!\n",
    "# Note: This dataset kinda sucks. It has some values in the \n",
    "\n",
    "# Logic for reading in Bitcoin tweets dataset.\n",
    "# btc_tweets = pd.read_csv('../bitcoin_tweets/Bitcoin_tweets.csv')\n",
    "# btc_tweets.drop([64943], axis=0, inplace=True)\n",
    "# btc_tweets.drop([137068], axis=0, inplace=True)\n",
    "# btc_tweets.drop([180575], axis=0, inplace=True)\n",
    "\n",
    "# btc_tweets.drop(btc_tweets.index[100000:len(btc_tweets)], inplace=True)\n",
    "# btc_tweets.drop(columns=['user_name', 'user_location', 'user_description', 'user_created', 'user_followers', 'user_friends', 'user_favourites', 'user_verified', 'source', 'is_retweet'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'c:\\Users\\WaKaBurd\\Documents\\GitHub\\CryptoPredictionTool\\search_results'\n",
    "for coin in hourly_coins: \n",
    "        os.chdir(path)\n",
    "        os.mkdir(coin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Twitter for data on all coins supplied by dataset\n",
    "---\n",
    "Below section of code searches through twitter using keywords. Uses sift_tweet() function to remove all unnecessary characters, links, emojis & words from tweets. Also uses Textblob to append polarity column to pandas df for tracking sentiment of tweets.\n",
    "\n",
    "### What to do next:\n",
    "* Search twitter based on Cashtags & Hashtags\n",
    "* Configure Twint with Google translater so I can translate tweets from non-english langauges to english. (Need to create ticket for this in Github)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing twitter search for coin: AAVE\n",
      "searching 2022-04-20 to 2022-04-24\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "performing twitter search for coin: AVAX\n",
      "searching 2022-04-20 to 2022-04-24\n",
      "performing twitter search for coin: BCH\n",
      "searching 2022-04-20 to 2022-04-24\n",
      "performing twitter search for coin: BTC\n",
      "searching 2022-04-20 to 2022-04-24\n",
      "performing twitter search for coin: ETH\n",
      "searching 2022-04-20 to 2022-04-24\n"
     ]
    }
   ],
   "source": [
    "# Function for iterating through coins list and storing findings in .csv files\n",
    "def search_coins(coins):\n",
    "    important_cols = ['date', 'created_at', 'tweet']\n",
    "    coin_counter = 0\n",
    "    \n",
    "    for coin in coins:\n",
    "        path = r'c:\\Users\\Brand\\OneDrive\\Documents\\GitHub\\CryptoPredictionTool\\search_results'\n",
    "        os.chdir(path)\n",
    "        #os.mkdir(coin)\n",
    "        os.chdir(coin)\n",
    "        \n",
    "        print('performing twitter search for coin:', coin)\n",
    "        \n",
    "        from_date = '2022-04-20'\n",
    "        to_date = '2022-04-24'\n",
    "        #coin = \"Bitcoin\"\n",
    "        print(f'searching {from_date} to {to_date}')\n",
    "        \n",
    "        c = twint.Config()\n",
    "        c.Limit = 3000\n",
    "        c.Lang = \"en\"\n",
    "        c.Pandas = True\n",
    "        c.Search = coin\n",
    "        c.Hide_output = True\n",
    "        c.Since = from_date\n",
    "        c.Until = to_date\n",
    "        c.Store_csv = True\n",
    "        c.Output = coin + '_' + from_date + '_' + to_date + '_search_result.csv'\n",
    "        twint.run.Search(c)\n",
    "\n",
    "\n",
    "# btc_tweets.text=btc_tweets.text.astype(str)\n",
    "# btc_tweets['Processed Tweet'] = btc_tweets['text'].apply(lambda x: sift_tweet(x.lower(), stopwords)) \n",
    "# btc_tweets['Polarity/Subjectivity'] = btc_tweets['Processed Tweet'].apply(lambda x: TextBlob(x).sentiment)            \n",
    "\n",
    "# btc_tweets\n",
    "\n",
    "search_coins(hourly_coins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below chunk is more data pre-processing. \n",
    "I need to modify the dataframe so that it contains both the price information, as well as all of the tweets so I can easily perform sentiment analysis on them using VADER.\n",
    "\n",
    "The code below will read all CSV files that were stored in both the hourly_prices directory (done earlier) as well as the tweets that are searchd for and stored in the search results folders for each currency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to create function for cleaning the tweets so we can derive the subjectivity and polarity using textblob.\n",
    "def sift_tweet(tweet, stop_words):\n",
    "    cleaned_tweet = tweet\n",
    "    cleaned_tweet = re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",tweet) # regex to remove all @userame, emojis, and links from tweets.\n",
    "    for word in cleaned_tweet:\n",
    "        if word in stop_words: cleaned_tweet.replace(word, '')\n",
    "    return cleaned_tweet\n",
    "\n",
    "def get_sentiment(text):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    sentiment = sia.polarity_scores(text)\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "os.chdir(r'C:\\Users\\Brand\\OneDrive\\Documents\\GitHub\\CryptoPredictionTool\\search_results')\n",
    "tweet_pds = []\n",
    "grouped_tweets = []\n",
    "\n",
    "# Read Tweets into a DF from the CSVs\n",
    "for coin in hourly_coins:\n",
    "    \n",
    "    os.chdir(r'C:\\Users\\Brand\\OneDrive\\Documents\\GitHub\\CryptoPredictionTool\\search_results')\n",
    "    os.chdir(coin)\n",
    "    csv_names = glob.glob('*.{}'.format(extension))\n",
    "    coin_pds = []\n",
    "    for file in csv_names:\n",
    "        tweet_pd = pd.read_csv(file)\n",
    "        tweet_pd.sort_values(by='date')\n",
    "        coin_pds.append(tweet_pd)\n",
    "    tweet_pds.append(coin_pds)\n",
    "\n",
    "\n",
    "#for i in range(len(tweet_pds)):\n",
    "# This is just so i can the data i need to train a model for aave and avax. I'll do all 5 when i want to showcase something but for now i only need these 2.\n",
    "for i in range(2):\n",
    "    print('lookin at coin number:', i)\n",
    "    hourly_coin_data[i]['date'] = pd.to_datetime(hourly_coin_data[i]['date'])\n",
    "    hourly_coin_data[i]['joined_tweets'] = np.nan\n",
    "    hourly_coin_data[i]['compound'] = np.nan\n",
    "    hourly_coin_data[i]['positive'] = np.nan\n",
    "    hourly_coin_data[i]['negative'] = np.nan\n",
    "    hourly_coin_data[i]['neutral'] = np.nan\n",
    "\n",
    "    #print(hourly_coin_data[i])\n",
    "    for j in range(len(tweet_pds[i])):\n",
    "        tweet_pds[i][j]['date'] = pd.to_datetime(tweet_pds[i][j]['date'])\n",
    "\n",
    "        for day in range(1,31):\n",
    "            #print('checking day:', day)\n",
    "            for hour in range(24):\n",
    "                tweet_time_mask = (tweet_pds[i][j]['date'].dt.hour >= hour) & (tweet_pds[i][j]['date'].dt.hour < hour + 1) & \\\n",
    "                            (tweet_pds[i][j]['date'].dt.day >= day ) & (tweet_pds[i][j]['date'].dt.day < day + 1)\n",
    "                price_time_mask = (hourly_coin_data[i]['date'].dt.hour >= hour) & (hourly_coin_data[i]['date'].dt.hour < hour + 1) & \\\n",
    "                            (hourly_coin_data[i]['date'].dt.day >= day ) & (hourly_coin_data[i]['date'].dt.day < day + 1)\n",
    "\n",
    "                hour_view = tweet_pds[i][j][tweet_time_mask]\n",
    "                if hour_view.empty:\n",
    "                    continue\n",
    "                \n",
    "                hour_view['cleaned_tweet'] = hour_view['tweet'].apply(lambda x: sift_tweet(str(x).lower(), stopwords))\n",
    "\n",
    "                joined_tweets = ' '.join(hour_view['tweet'])\n",
    "                joined_clean_tweets = ' '.join(hour_view['cleaned_tweet'])\n",
    "\n",
    "                SIA = get_sentiment(joined_tweets)\n",
    "                compound = SIA['compound']                    # Score representing sum(lexicon ratings)\n",
    "                pos = SIA['pos']\n",
    "                neg = SIA['neg']\n",
    "                neu = SIA['neu']\n",
    "\n",
    "                index = hourly_coin_data[i][price_time_mask].index\n",
    "                for ind in index:\n",
    "                    hourly_coin_data[i].at[ind,'joined_tweets'] = joined_tweets\n",
    "                    hourly_coin_data[i].at[ind,'polarity'] = TextBlob(joined_clean_tweets).sentiment[0]            # Lambda function for creating Polarity value in Coin Dataframe using Textblob\n",
    "                    hourly_coin_data[i].at[ind,'subjectivity'] = TextBlob(joined_clean_tweets).sentiment[1]            # Lambda function for creating Polarity value in Coin Dataframe using Textblob\n",
    "                    hourly_coin_data[i].at[ind,'compound'] = compound\n",
    "                    hourly_coin_data[i].at[ind,'positive'] = pos\n",
    "                    hourly_coin_data[i].at[ind,'negative'] = neg\n",
    "                    hourly_coin_data[i].at[ind,'neutral'] = neu\n",
    "                \n",
    "                #Processing twitter live tweets\n",
    "\n",
    "\n",
    "                # hourly_coin_data[i]['Polarity'] = hourly_coin_data[i]['Processed Tweet'].apply(lambda x: TextBlob(x).sentiment[0])            # Lambda function for creating Polarity value in Coin Dataframe using Textblob\n",
    "                # hourly_coin_data[i]['Subjectivity'] = hourly_coin_data[i]['Processed Tweet'].apply(lambda x: TextBlob(x).sentiment[1])            # Lambda function for creating Polarity value in Coin Dataframe using Textblob\n",
    "\n",
    "                \n",
    "\n",
    "    hourly_coin_data[i] = hourly_coin_data[i][hourly_coin_data[i]['joined_tweets'].notna()]     # Drop all NAN rows (rows we don't have tweets for)\n",
    "\n",
    "print(len(tweet_pds[0]))\n",
    "#pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appending a label to each row signifying an increase/decrease in price during that hour. \n",
    "\n",
    "If the price increases/no change we append a 1 to the price change column for that row, if it decreases we append a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(hourly_coin_data)):\n",
    "    hourly_coin_data[i].reset_index()\n",
    "    hourly_coin_data[i]['price_change'] = np.nan\n",
    "    for index, row in hourly_coin_data[i].iterrows():\n",
    "        if row.open > row.close:\n",
    "            hourly_coin_data[i].at[index, 'price_change'] = 0\n",
    "        else:\n",
    "            hourly_coin_data[i].at[index, 'price_change'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_coin_data[1].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Train Neural Net on Dataset (Attempt 1)\n",
    "---\n",
    "\n",
    "\n",
    "### What to do next:\n",
    "* Probably attempt it differently. Outcomes are horrid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proper Implementation: LDA With Sentiment Analysis\n",
    "---\n",
    "Yeah the last one wasn't good. This one is ight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTANT:\n",
    "---\n",
    "* If you're running each cell in the jupyter notebook, you only need to run the below code cell. \n",
    "\n",
    "* If you're going to try to use the exported model_df_#.csv files that are saved in the hourly_coin_data directory, you need to run the 2nd cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all the columns we actually want to keep for the purposes of training & using the model.\n",
    "model_cols = ['open', 'high', 'low', 'Volume USD', 'compound', 'positive', 'negative', 'neutral', 'polarity', 'subjectivity', 'price_change']\n",
    "os.chdir(r'C:\\Users\\Brand\\OneDrive\\Documents\\GitHub\\CryptoPredictionTool\\hourly_coin_data')\n",
    "\n",
    "for i in range(len(hourly_coin_data)):\n",
    "\n",
    "    model_df = hourly_coin_data[i][model_cols]\n",
    "    model_df.to_csv(f'model_df_{i}.csv')\n",
    "\n",
    "    # Feature Dataset\n",
    "    x = model_df\n",
    "    # Target Dataset\n",
    "    y = np.array(model_df['price_change'])\n",
    "    x.drop(['price_change'], axis=1, inplace=True)\n",
    "    np.asarray(x)\n",
    "    \n",
    "    print(x)\n",
    "\n",
    "    # split into test & train\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    # Create svm model\n",
    "    model = LinearDiscriminantAnalysis().fit(x_train, y_train)\n",
    "    predictions = model.predict(x_test)\n",
    "    print(classification_report(y_test, predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         8\n",
      "         1.0       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drop_this</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>Volume USD</th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>167</td>\n",
       "      <td>335.35</td>\n",
       "      <td>336.76</td>\n",
       "      <td>335.35</td>\n",
       "      <td>5706.570785</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.240060</td>\n",
       "      <td>0.494071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>153</td>\n",
       "      <td>337.06</td>\n",
       "      <td>338.63</td>\n",
       "      <td>335.41</td>\n",
       "      <td>97015.493435</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.190470</td>\n",
       "      <td>0.419283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>161</td>\n",
       "      <td>336.83</td>\n",
       "      <td>338.05</td>\n",
       "      <td>334.71</td>\n",
       "      <td>42951.315335</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.168569</td>\n",
       "      <td>0.431612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>160</td>\n",
       "      <td>337.36</td>\n",
       "      <td>337.36</td>\n",
       "      <td>335.20</td>\n",
       "      <td>42411.145100</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.156792</td>\n",
       "      <td>0.417346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>61</td>\n",
       "      <td>300.85</td>\n",
       "      <td>304.23</td>\n",
       "      <td>300.73</td>\n",
       "      <td>105113.895379</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.155237</td>\n",
       "      <td>0.433443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>68</td>\n",
       "      <td>299.99</td>\n",
       "      <td>302.71</td>\n",
       "      <td>299.97</td>\n",
       "      <td>23777.237648</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.183173</td>\n",
       "      <td>0.456338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>172</td>\n",
       "      <td>335.56</td>\n",
       "      <td>336.15</td>\n",
       "      <td>334.56</td>\n",
       "      <td>33532.113582</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.112222</td>\n",
       "      <td>0.425595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>72</td>\n",
       "      <td>295.64</td>\n",
       "      <td>297.73</td>\n",
       "      <td>293.52</td>\n",
       "      <td>58667.819981</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.212316</td>\n",
       "      <td>0.452137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>174</td>\n",
       "      <td>336.18</td>\n",
       "      <td>337.81</td>\n",
       "      <td>335.65</td>\n",
       "      <td>66574.166401</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.156948</td>\n",
       "      <td>0.390343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>168</td>\n",
       "      <td>336.11</td>\n",
       "      <td>337.42</td>\n",
       "      <td>334.95</td>\n",
       "      <td>72929.736211</td>\n",
       "      <td>0.9966</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.176491</td>\n",
       "      <td>0.441728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>69</td>\n",
       "      <td>298.25</td>\n",
       "      <td>299.96</td>\n",
       "      <td>298.15</td>\n",
       "      <td>58653.176666</td>\n",
       "      <td>0.8952</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.385918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>157</td>\n",
       "      <td>332.56</td>\n",
       "      <td>332.56</td>\n",
       "      <td>329.65</td>\n",
       "      <td>73603.366963</td>\n",
       "      <td>0.9989</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.127373</td>\n",
       "      <td>0.434664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>156</td>\n",
       "      <td>330.35</td>\n",
       "      <td>330.81</td>\n",
       "      <td>328.64</td>\n",
       "      <td>22996.994294</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.124359</td>\n",
       "      <td>0.479441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>70</td>\n",
       "      <td>297.94</td>\n",
       "      <td>298.49</td>\n",
       "      <td>295.70</td>\n",
       "      <td>64481.743698</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.283361</td>\n",
       "      <td>0.453835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>169</td>\n",
       "      <td>337.35</td>\n",
       "      <td>339.01</td>\n",
       "      <td>336.07</td>\n",
       "      <td>75115.598316</td>\n",
       "      <td>0.9986</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.147384</td>\n",
       "      <td>0.438524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>74</td>\n",
       "      <td>292.06</td>\n",
       "      <td>296.61</td>\n",
       "      <td>291.65</td>\n",
       "      <td>60730.646325</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.198225</td>\n",
       "      <td>0.428493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>240</td>\n",
       "      <td>375.62</td>\n",
       "      <td>375.78</td>\n",
       "      <td>372.78</td>\n",
       "      <td>41919.821213</td>\n",
       "      <td>-0.5621</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.927</td>\n",
       "      <td>-0.058414</td>\n",
       "      <td>0.376169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>62</td>\n",
       "      <td>301.84</td>\n",
       "      <td>301.91</td>\n",
       "      <td>300.53</td>\n",
       "      <td>29934.510682</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.183970</td>\n",
       "      <td>0.458928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>67</td>\n",
       "      <td>302.89</td>\n",
       "      <td>304.85</td>\n",
       "      <td>302.55</td>\n",
       "      <td>23314.881614</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.195313</td>\n",
       "      <td>0.439148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>144</td>\n",
       "      <td>323.55</td>\n",
       "      <td>325.79</td>\n",
       "      <td>321.72</td>\n",
       "      <td>110131.293710</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.157845</td>\n",
       "      <td>0.445643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>59</td>\n",
       "      <td>306.93</td>\n",
       "      <td>307.29</td>\n",
       "      <td>305.57</td>\n",
       "      <td>63218.540965</td>\n",
       "      <td>0.9984</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.128626</td>\n",
       "      <td>0.485959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>71</td>\n",
       "      <td>296.47</td>\n",
       "      <td>299.72</td>\n",
       "      <td>296.41</td>\n",
       "      <td>39562.182858</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.263801</td>\n",
       "      <td>0.549872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>163</td>\n",
       "      <td>336.46</td>\n",
       "      <td>337.30</td>\n",
       "      <td>336.44</td>\n",
       "      <td>41785.465142</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.186738</td>\n",
       "      <td>0.462437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>166</td>\n",
       "      <td>336.38</td>\n",
       "      <td>337.73</td>\n",
       "      <td>336.38</td>\n",
       "      <td>6061.558078</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.123566</td>\n",
       "      <td>0.396700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>305.72</td>\n",
       "      <td>306.31</td>\n",
       "      <td>302.69</td>\n",
       "      <td>52545.313968</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.186116</td>\n",
       "      <td>0.440424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>66</td>\n",
       "      <td>305.32</td>\n",
       "      <td>305.56</td>\n",
       "      <td>301.80</td>\n",
       "      <td>81547.827851</td>\n",
       "      <td>0.9947</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.129734</td>\n",
       "      <td>0.404333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>164</td>\n",
       "      <td>336.91</td>\n",
       "      <td>336.91</td>\n",
       "      <td>336.46</td>\n",
       "      <td>12078.516025</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.105241</td>\n",
       "      <td>0.443035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>120</td>\n",
       "      <td>325.44</td>\n",
       "      <td>325.85</td>\n",
       "      <td>325.08</td>\n",
       "      <td>3733.263843</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.113962</td>\n",
       "      <td>0.444908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60</td>\n",
       "      <td>303.78</td>\n",
       "      <td>306.21</td>\n",
       "      <td>302.38</td>\n",
       "      <td>95267.105920</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.150074</td>\n",
       "      <td>0.448230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>77</td>\n",
       "      <td>303.86</td>\n",
       "      <td>303.86</td>\n",
       "      <td>298.88</td>\n",
       "      <td>28944.407221</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.095812</td>\n",
       "      <td>0.453252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>162</td>\n",
       "      <td>336.75</td>\n",
       "      <td>337.81</td>\n",
       "      <td>335.22</td>\n",
       "      <td>54644.793878</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.192746</td>\n",
       "      <td>0.467324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>75</td>\n",
       "      <td>296.23</td>\n",
       "      <td>297.00</td>\n",
       "      <td>290.42</td>\n",
       "      <td>64007.689850</td>\n",
       "      <td>0.9993</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.199513</td>\n",
       "      <td>0.439101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>73</td>\n",
       "      <td>295.67</td>\n",
       "      <td>296.48</td>\n",
       "      <td>294.30</td>\n",
       "      <td>26569.424050</td>\n",
       "      <td>0.9922</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.095758</td>\n",
       "      <td>0.342771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>63</td>\n",
       "      <td>303.01</td>\n",
       "      <td>303.02</td>\n",
       "      <td>301.22</td>\n",
       "      <td>58121.843058</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.186194</td>\n",
       "      <td>0.524917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>165</td>\n",
       "      <td>336.57</td>\n",
       "      <td>337.33</td>\n",
       "      <td>335.55</td>\n",
       "      <td>11182.267781</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.266306</td>\n",
       "      <td>0.486481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>175</td>\n",
       "      <td>335.62</td>\n",
       "      <td>336.99</td>\n",
       "      <td>334.57</td>\n",
       "      <td>20193.564617</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.211111</td>\n",
       "      <td>0.563426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>304.21</td>\n",
       "      <td>305.03</td>\n",
       "      <td>304.21</td>\n",
       "      <td>4622.890264</td>\n",
       "      <td>0.9893</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.150936</td>\n",
       "      <td>0.408274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>341.28</td>\n",
       "      <td>343.48</td>\n",
       "      <td>341.22</td>\n",
       "      <td>60241.801959</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.150689</td>\n",
       "      <td>0.441667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>173</td>\n",
       "      <td>337.19</td>\n",
       "      <td>337.47</td>\n",
       "      <td>335.44</td>\n",
       "      <td>36429.389512</td>\n",
       "      <td>0.9982</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.134606</td>\n",
       "      <td>0.382011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>170</td>\n",
       "      <td>335.47</td>\n",
       "      <td>337.07</td>\n",
       "      <td>335.47</td>\n",
       "      <td>46809.699163</td>\n",
       "      <td>0.9982</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.176901</td>\n",
       "      <td>0.455025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    drop_this    open    high     low     Volume USD  compound  positive  \\\n",
       "41        167  335.35  336.76  335.35    5706.570785    0.9981     0.082   \n",
       "27        153  337.06  338.63  335.41   97015.493435    0.9991     0.099   \n",
       "35        161  336.83  338.05  334.71   42951.315335    0.9996     0.111   \n",
       "34        160  337.36  337.36  335.20   42411.145100    0.9999     0.126   \n",
       "7          61  300.85  304.23  300.73  105113.895379    0.9997     0.118   \n",
       "14         68  299.99  302.71  299.97   23777.237648    0.9995     0.101   \n",
       "46        172  335.56  336.15  334.56   33532.113582    0.9974     0.079   \n",
       "18         72  295.64  297.73  293.52   58667.819981    0.9972     0.100   \n",
       "48        174  336.18  337.81  335.65   66574.166401    0.9996     0.122   \n",
       "42        168  336.11  337.42  334.95   72929.736211    0.9966     0.073   \n",
       "15         69  298.25  299.96  298.15   58653.176666    0.8952     0.052   \n",
       "31        157  332.56  332.56  329.65   73603.366963    0.9989     0.096   \n",
       "30        156  330.35  330.81  328.64   22996.994294    0.9997     0.117   \n",
       "16         70  297.94  298.49  295.70   64481.743698    0.9996     0.115   \n",
       "43        169  337.35  339.01  336.07   75115.598316    0.9986     0.092   \n",
       "20         74  292.06  296.61  291.65   60730.646325    0.9978     0.070   \n",
       "50        240  375.62  375.78  372.78   41919.821213   -0.5621     0.035   \n",
       "8          62  301.84  301.91  300.53   29934.510682    0.9997     0.111   \n",
       "13         67  302.89  304.85  302.55   23314.881614    0.9997     0.118   \n",
       "25        144  323.55  325.79  321.72  110131.293710    1.0000     0.108   \n",
       "5          59  306.93  307.29  305.57   63218.540965    0.9984     0.064   \n",
       "17         71  296.47  299.72  296.41   39562.182858    0.9997     0.139   \n",
       "37        163  336.46  337.30  336.44   41785.465142    0.9998     0.126   \n",
       "40        166  336.38  337.73  336.38    6061.558078    0.9875     0.065   \n",
       "1          48  305.72  306.31  302.69   52545.313968    1.0000     0.103   \n",
       "12         66  305.32  305.56  301.80   81547.827851    0.9947     0.072   \n",
       "38        164  336.91  336.91  336.46   12078.516025    0.9997     0.102   \n",
       "24        120  325.44  325.85  325.08    3733.263843    1.0000     0.092   \n",
       "6          60  303.78  306.21  302.38   95267.105920    0.9996     0.103   \n",
       "23         77  303.86  303.86  298.88   28944.407221    0.9988     0.115   \n",
       "36        162  336.75  337.81  335.22   54644.793878    0.9999     0.146   \n",
       "21         75  296.23  297.00  290.42   64007.689850    0.9993     0.119   \n",
       "19         73  295.67  296.48  294.30   26569.424050    0.9922     0.061   \n",
       "9          63  303.01  303.02  301.22   58121.843058    0.9997     0.117   \n",
       "39        165  336.57  337.33  335.55   11182.267781    0.9995     0.109   \n",
       "49        175  335.62  336.99  334.57   20193.564617    0.9924     0.118   \n",
       "3          57  304.21  305.03  304.21    4622.890264    0.9893     0.055   \n",
       "0          24  341.28  343.48  341.22   60241.801959    1.0000     0.099   \n",
       "47        173  337.19  337.47  335.44   36429.389512    0.9982     0.071   \n",
       "44        170  335.47  337.07  335.47   46809.699163    0.9982     0.082   \n",
       "\n",
       "    negative  neutral  polarity  subjectivity  \n",
       "41     0.028    0.890  0.240060      0.494071  \n",
       "27     0.041    0.860  0.190470      0.419283  \n",
       "35     0.052    0.837  0.168569      0.431612  \n",
       "34     0.029    0.845  0.156792      0.417346  \n",
       "7      0.059    0.823  0.155237      0.433443  \n",
       "14     0.034    0.866  0.183173      0.456338  \n",
       "46     0.034    0.887  0.112222      0.425595  \n",
       "18     0.069    0.831  0.212316      0.452137  \n",
       "48     0.045    0.833  0.156948      0.390343  \n",
       "42     0.037    0.890  0.176491      0.441728  \n",
       "15     0.045    0.904  0.076190      0.385918  \n",
       "31     0.060    0.844  0.127373      0.434664  \n",
       "30     0.053    0.830  0.124359      0.479441  \n",
       "16     0.035    0.849  0.283361      0.453835  \n",
       "43     0.024    0.884  0.147384      0.438524  \n",
       "20     0.028    0.903  0.198225      0.428493  \n",
       "50     0.039    0.927 -0.058414      0.376169  \n",
       "8      0.028    0.861  0.183970      0.458928  \n",
       "13     0.057    0.824  0.195313      0.439148  \n",
       "25     0.039    0.853  0.157845      0.445643  \n",
       "5      0.035    0.901  0.128626      0.485959  \n",
       "17     0.051    0.810  0.263801      0.549872  \n",
       "37     0.058    0.815  0.186738      0.462437  \n",
       "40     0.045    0.890  0.123566      0.396700  \n",
       "1      0.049    0.848  0.186116      0.440424  \n",
       "12     0.046    0.882  0.129734      0.404333  \n",
       "38     0.026    0.872  0.105241      0.443035  \n",
       "24     0.041    0.867  0.113962      0.444908  \n",
       "6      0.049    0.848  0.150074      0.448230  \n",
       "23     0.060    0.824  0.095812      0.453252  \n",
       "36     0.036    0.818  0.192746      0.467324  \n",
       "21     0.028    0.853  0.199513      0.439101  \n",
       "19     0.034    0.905  0.095758      0.342771  \n",
       "9      0.034    0.850  0.186194      0.524917  \n",
       "39     0.029    0.862  0.266306      0.486481  \n",
       "49     0.073    0.809  0.211111      0.563426  \n",
       "3      0.021    0.924  0.150936      0.408274  \n",
       "0      0.053    0.848  0.150689      0.441667  \n",
       "47     0.026    0.903  0.134606      0.382011  \n",
       "44     0.027    0.890  0.176901      0.455025  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are all the columns we actually want to keep for the purposes of training & using the model.\n",
    "model_cols = ['open', 'high', 'low', 'Volume USD', 'compound', 'positive', 'negative', 'neutral', 'polarity', 'subjectivity', 'price_change']\n",
    "os.chdir(r'C:\\Users\\Brand\\OneDrive\\Documents\\GitHub\\CryptoPredictionTool\\hourly_coin_data')\n",
    "\n",
    "model_df = pd.read_csv('model_df_2.csv')\n",
    "# Feature Dataset\n",
    "x = model_df\n",
    "# Target Dataset\n",
    "y = np.array(model_df['price_change'])\n",
    "x.drop(['price_change'], axis=1, inplace=True)\n",
    "np.asarray(x)\n",
    "\n",
    "\n",
    "# split into test & train\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "# Create svm model\n",
    "model = LinearDiscriminantAnalysis().fit(x_train, y_train)\n",
    "predictions = model.predict(x_test)\n",
    "print(classification_report(y_test, predictions))\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull data from the last hour to make prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing twitter search for coin: AVAX lang:en\n",
      "searching 2022-04-24 21:38:08 to 2022-04-24 22:37:38\n",
      "Endpoint response code:200\n"
     ]
    }
   ],
   "source": [
    "def send_request(url, headers, params, next_token=None):\n",
    "    params['next_token'] = next_token\n",
    "    response = requests.request('GET', url, headers=headers, params=params)\n",
    "    print('Endpoint response code:' + str(response.status_code))\n",
    "    if (response.status_code != 200):\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "def pull_live_tweets(coin):\n",
    "\n",
    "    # Pull tweets from the last hour\n",
    "    path = r'c:\\Users\\Brand\\OneDrive\\Documents\\GitHub\\CryptoPredictionTool\\predicted_trends'\n",
    "    os.chdir(path)\n",
    "    #os.chdir(coin)\n",
    "\n",
    "    print('performing twitter search for coin:', coin)\n",
    "\n",
    "    # 1 hour ago\n",
    "    from_date = datetime.now(timezone.utc) - timedelta(hours = 1)\n",
    "    to_date = datetime.now(timezone.utc) + timedelta(seconds=-30)\n",
    "    \n",
    "    iso_from_date = from_date.isoformat()\n",
    "    iso_to_date = to_date.isoformat()\n",
    "\n",
    "    from_date = from_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    to_date = to_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    print(f'searching {from_date} to {to_date}')\n",
    "    \n",
    "    bearer_token = 'AAAAAAAAAAAAAAAAAAAAAJwBbgEAAAAAyi3tWb4jDN72EZqz6dcWgOIizuc%3DsC3xrWGrxPCwiKwqy2fINUgJDs2qKaZNlITIIy75Pss1oiMeTN'\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": \"Bearer {}\".format(bearer_token)\n",
    "    }\n",
    "\n",
    "    url = 'https://api.twitter.com/2/tweets/search/recent'\n",
    "\n",
    "    params = {\n",
    "        'query': coin,\n",
    "        'start_time': iso_from_date,\n",
    "        'end_time': iso_to_date,\n",
    "        'max_results': 100,\n",
    "        'next_token':{}\n",
    "    }\n",
    "\n",
    "    json_response = send_request(url, headers, params)\n",
    "    return json_response\n",
    "\n",
    "# Pull tweets on topic from last 30 minutes\n",
    "fetched_tweets = pull_live_tweets('AVAX lang:en')\n",
    "fetched_tweets_df = pd.DataFrame(fetched_tweets['data'])\n",
    "fetched_tweets_df.to_csv('recently_fetched_tweets.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull financial data from yahoo finance for the current hour\n",
    "# Uses AlphaVantage API with their CRYPTO_INTRADAY endpoint.\n",
    "\n",
    "av_api_key = 'GD982KLZ6PZ69GQ0'\n",
    "path = r'c:\\Users\\Brand\\OneDrive\\Documents\\GitHub\\CryptoPredictionTool\\prices\\LivePrices'\n",
    "os.chdir(path)\n",
    "\n",
    "def get_prices(coin):\n",
    "    url = f'https://www.alphavantage.co/query?function=CRYPTO_INTRADAY&symbol={coin}&market=USD&interval=1min&apikey={av_api_key}&datatype=csv'\n",
    "    req = requests.get(url)\n",
    "    data = req.content\n",
    "    csv_file = open(f'{coin}_prices.csv','wb')\n",
    "    csv_file.write(data)\n",
    "    csv_file.close()\n",
    "    return\n",
    "\n",
    "get_prices('AVAX')  # Get the prices from the specified coin\n",
    "\n",
    "# format that data into a dataframe\n",
    "live_prices = pd.read_csv('AVAX_prices.csv')    # read in live prices csv\n",
    "kept_prices = live_prices.head(60)              # keep only the last 60 minutes.\n",
    "high = kept_prices['high'].max(axis=0)       # Find the max value in the last 60 minutes\n",
    "low = kept_prices['low'].min(axis=0)        # find the lowesst value in the last 60 minutes\n",
    "open_price = kept_prices['open'].values[59]                 # Price from 60 minutes ago. (opening price of the last hour) \n",
    "volume = kept_prices['volume'].sum(axis=0)      # summate the total volume traded from the last hour\n",
    "\n",
    "live_coin_data = pd.DataFrame([[open_price, high, low, volume]], columns =['open', 'high', 'low', 'volume'])\n",
    "\n",
    "# Run textblob on tweets for polarity & subjectivity\n",
    "combined_tweets = ' '.join(fetched_tweets_df['text'])\n",
    "\n",
    "# Clean tweet so we can use textblob on it.\n",
    "fetched_tweets_df['cleaned_tweet'] = fetched_tweets_df['text'].apply(lambda x: sift_tweet(str(x).lower(), stopwords))\n",
    "combined_cleaned_tweets = ' '.join(fetched_tweets_df['cleaned_tweet'])\n",
    "\n",
    "            \n",
    "\n",
    "# Get sentiment values on tweets using VADER sentiment analyzer\n",
    "sia = get_sentiment(combined_tweets)\n",
    "compound = sia['compound']                    # Score representing sum(lexicon ratings)\n",
    "pos = sia['pos']\n",
    "neg = sia['neg']\n",
    "neu = sia['neu']\n",
    "\n",
    "live_coin_data.loc[live_coin_data.index[0],'compound'] = compound  \n",
    "live_coin_data.loc[live_coin_data.index[0],'pos'] = pos          \n",
    "live_coin_data.loc[live_coin_data.index[0],'neg'] = neg            \n",
    "live_coin_data.loc[live_coin_data.index[0],'neu'] = neu \n",
    "live_coin_data.loc[live_coin_data.index[0],'polarity'] = TextBlob(combined_cleaned_tweets).sentiment[0]            \n",
    "live_coin_data.loc[live_coin_data.index[0],'subjectivity'] = TextBlob(combined_cleaned_tweets).sentiment[1]\n",
    "\n",
    "live_coin_data\n",
    "\n",
    "# make the prediction\n",
    "model.predict(live_coin_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! The above cell outputs the prediction from the model. \n",
    "\n",
    "* 0-> Price going down,\n",
    "* 1-> Price going up!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b4c0bf06c6142ddc920bc4833060833a5c39c864bf9bfacfcb217d05e37f17a2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
