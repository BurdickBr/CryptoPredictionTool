{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Statements\n",
    "---\n",
    "**Important note:**\n",
    "For some reason tensorflow version and numpy version have dependency conflicts. Need to figure out what version is stable for both of these to work together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd                 # Pandas dataframe library\n",
    "import pandas_datareader as pdr     # Pandas datareader that allows me to lookup & store live crypto prices from yahoo finance.\n",
    "import numpy as np                  # Numpy\n",
    "import matplotlib.pyplot as pypl    # Pyplot used to create visuals/graphics based on data \n",
    "from alpha_vantage.timeseries import TimeSeries     # Library used for pulling live price data from alphavantage api\n",
    "\n",
    "from datetime import datetime, timedelta, timezone             # Datetime library.\n",
    "import pytz\n",
    "import json\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=ResourceWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import glob                         # For changing/finding proper directory\n",
    "import os                           # For changing/finding proper directory (when opening files)\n",
    "import requests\n",
    "import twint                        # Twitter web scraping tool with more features than the regular twitter API\n",
    "import nest_asyncio                 # Import required for twint usage.\n",
    "nest_asyncio.apply()                \n",
    "\n",
    "import re                           # Regex for string cleaning (used for Textblob Sentiment Analysis)\n",
    "from textblob import TextBlob       # Textblob used for sentiment analysis of cleaned data.\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer    # Sentiment analysis tool that works great on determining social media sentiment.\n",
    "from newsapi import NewsApiClient   # NewsApiClient lets me look up/pull news articles relating to specified topics.\n",
    "import requests                     # Used for sending get requests to the NewsAPI client.\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler                          # Scaler used for scaling data (LSTMRNN Implementation)\n",
    "from sklearn.metrics import accuracy_score, classification_report       \n",
    "from sklearn.model_selection import train_test_split                    # Used for splitting data\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis    # Used for implementing SVM\n",
    "import tensorflow as tf                                                 # TF used for LSTMRNN Implmentation\n",
    "from keras.layers import Dense, Dropout, LSTM                           # Dense, dropout & lstm used for creating LSTMRNN \n",
    "from keras.models import Sequential                                     # Important because we're working with Sequential data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in crypto price dataset\n",
    "---\n",
    "Section below reads csv files into pandas dataframes for interacting with. Also compiles list of coin names for twitter searching.\n",
    "\n",
    "### What to do next:\n",
    "* Retrieve Token labels from CSV file for searching by Cashtag on twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'c:\\Users\\Brand\\OneDrive\\Documents\\GitHub\\CryptoPredictionTool\\prices\\DailyPrices'\n",
    "extension = 'csv'\n",
    "os.chdir(path)\n",
    "daily_csv_files = glob.glob('*.{}'.format(extension))\n",
    "\n",
    "\n",
    "path = r'c:\\Users\\Brand\\OneDrive\\Documents\\GitHub\\CryptoPredictionTool\\prices\\HourlyPrices'\n",
    "os.chdir(path)\n",
    "hourly_csv_files = glob.glob('*.{}'.format(extension))\n",
    "\n",
    "# Compile list of all coin names for searching on twitter later\n",
    "daily_coins = []\n",
    "hourly_coins = []\n",
    "\n",
    "for coin in daily_csv_files:\n",
    "    vals = coin.split(\"_\")\n",
    "    coin_name = vals[1][:-4]\n",
    "    daily_coins.append(coin_name)\n",
    "\n",
    "for coin in hourly_csv_files:\n",
    "    vals = coin.split(\"_\")\n",
    "    coin_name = vals[0]\n",
    "    hourly_coins.append(coin_name)\n",
    "\n",
    "# compile list of pandas dataframes for use later.\n",
    "hourly_coin_data = []\n",
    "\n",
    "for file in hourly_csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    hourly_coin_data.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           unix                date    symbol    open    high     low   close  \\\n",
      "24   1649894400 2022-04-14 00:00:00  AAVE/USD  177.74  178.82  177.74  178.82   \n",
      "48   1649808000 2022-04-13 00:00:00  AAVE/USD  165.00  167.89  165.00  167.89   \n",
      "56   1649779200 2022-04-12 16:00:00  AAVE/USD  166.58  168.31  165.97  165.97   \n",
      "57   1649775600 2022-04-12 15:00:00  AAVE/USD  166.00  168.02  166.00  167.64   \n",
      "58   1649772000 2022-04-12 14:00:00  AAVE/USD  169.74  170.29  164.42  166.01   \n",
      "..          ...                 ...       ...     ...     ...     ...     ...   \n",
      "196  1649275200 2022-04-06 20:00:00  AAVE/USD  198.44  198.44  197.38  198.23   \n",
      "197  1649271600 2022-04-06 19:00:00  AAVE/USD  199.76  199.97  196.41  197.18   \n",
      "198  1649268000 2022-04-06 18:00:00  AAVE/USD  196.94  197.98  193.62  197.98   \n",
      "199  1649264400 2022-04-06 17:00:00  AAVE/USD  193.67  193.83  193.21  193.83   \n",
      "240  1649116800 2022-04-05 00:00:00  AAVE/USD  236.79  236.79  235.36  235.56   \n",
      "\n",
      "     Volume AAVE     Volume USD  \\\n",
      "24     10.454072    1869.397139   \n",
      "48     68.652793   11526.117413   \n",
      "56     92.205446   15303.337894   \n",
      "57     80.111635   13429.914508   \n",
      "58    199.818111   33171.804532   \n",
      "..           ...            ...   \n",
      "196   321.665764   63763.804406   \n",
      "197   525.512568  103620.568202   \n",
      "198   437.102271   86537.507634   \n",
      "199    57.526844   11150.428138   \n",
      "240     1.780000     419.296800   \n",
      "\n",
      "                                         joined_tweets  compound  positive  \\\n",
      "24   @pixelsebi @AaveAave @Milkomeda_com @avalanche...    0.9998     0.094   \n",
      "48   @DNCHI77 in my anecdotal experience growing up...    1.0000     0.102   \n",
      "56   Can‚Äôt believe it took so long for people in th...   -0.9944     0.083   \n",
      "57   @FinesseEness Recommended study material for t...   -0.9940     0.087   \n",
      "58   @Uniswap @AaveAave @compoundfinance @MakerDAO ...   -0.9954     0.077   \n",
      "..                                                 ...       ...       ...   \n",
      "196  $AAVE | LTF | 1h  üëÄü§ù 195$ &gt; 218$ &gt; 242$ ...    0.9889     0.092   \n",
      "197  @VikrantGarg89 @vermagashish @Amrinde94577929 ...    0.9266     0.070   \n",
      "198  $AAVE Don't miss the next move in a few hours:...    0.9977     0.096   \n",
      "199  Gut tells me the rest of the year will be infi...    0.9834     0.065   \n",
      "240  Aave (AAVE) Anlƒ±k Fiyat: 221,34USDT G√ºnl√ºk Deƒü...   -0.8137     0.061   \n",
      "\n",
      "     negative  neutral  polarity  subjectivity  price_change  \n",
      "24      0.068    0.838  0.064416      0.471246           1.0  \n",
      "48      0.066    0.832  0.076136      0.424129           1.0  \n",
      "56      0.094    0.823  0.038651      0.465325           0.0  \n",
      "57      0.097    0.816  0.038002      0.415383           1.0  \n",
      "58      0.084    0.838  0.041573      0.419930           0.0  \n",
      "..        ...      ...       ...           ...           ...  \n",
      "196     0.059    0.849  0.034420      0.505499           0.0  \n",
      "197     0.057    0.873  0.067508      0.389942           0.0  \n",
      "198     0.056    0.848  0.109864      0.459019           1.0  \n",
      "199     0.050    0.885  0.038491      0.425467           1.0  \n",
      "240     0.069    0.871  0.005424      0.354840           0.0  \n",
      "\n",
      "[70 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "print(hourly_coin_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE:* The cell below is for reading in the Bitcoin tweets dataset from Kaggle. (https://www.kaggle.com/datasets/kaushiksuresh147/bitcoin-tweets)\n",
    "This datset kinda sucks though. For a few reasons:\n",
    "* Firstly, its tweets span 1.5 years but are only from 43 total days, making it inconsistent to use with Sequential data, like the price history.\n",
    "* Secondly, it has some values in impropere columns (namely tag values in the date column) which have to be manually removed.\n",
    "* Lastly, its huge. 280k tweets. Which at first seems great, but being that the sample size itself is incredibly sparse in terms of date-span, this leads to problems with implementation. \n",
    "\n",
    "I'll leave it here in a cell in case I decide to use it later, but for now, it doesn't apply to this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!! BELOW IS THE LOGIC FOR READING IN THE TWEETS FROM THE BITCOIN TWEET KAGGLE DATASET !!!\n",
    "# Note: This dataset kinda sucks. It has some values in the \n",
    "\n",
    "# Logic for reading in Bitcoin tweets dataset.\n",
    "# btc_tweets = pd.read_csv('../bitcoin_tweets/Bitcoin_tweets.csv')\n",
    "# btc_tweets.drop([64943], axis=0, inplace=True)\n",
    "# btc_tweets.drop([137068], axis=0, inplace=True)\n",
    "# btc_tweets.drop([180575], axis=0, inplace=True)\n",
    "\n",
    "# btc_tweets.drop(btc_tweets.index[100000:len(btc_tweets)], inplace=True)\n",
    "# btc_tweets.drop(columns=['user_name', 'user_location', 'user_description', 'user_created', 'user_followers', 'user_friends', 'user_favourites', 'user_verified', 'source', 'is_retweet'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'c:\\\\Users\\\\WaKaBurd\\\\Documents\\\\GitHub\\\\CryptoPredictionTool\\\\search_results'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Brand\\OneDrive\\Documents\\GitHub\\CryptoPredictionTool\\CryptoPredictionTool.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Brand/OneDrive/Documents/GitHub/CryptoPredictionTool/CryptoPredictionTool.ipynb#ch0000007?line=0'>1</a>\u001b[0m path \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mc:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mWaKaBurd\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDocuments\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mGitHub\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mCryptoPredictionTool\u001b[39m\u001b[39m\\\u001b[39m\u001b[39msearch_results\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Brand/OneDrive/Documents/GitHub/CryptoPredictionTool/CryptoPredictionTool.ipynb#ch0000007?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m coin \u001b[39min\u001b[39;00m hourly_coins: \n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Brand/OneDrive/Documents/GitHub/CryptoPredictionTool/CryptoPredictionTool.ipynb#ch0000007?line=2'>3</a>\u001b[0m         os\u001b[39m.\u001b[39;49mchdir(path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Brand/OneDrive/Documents/GitHub/CryptoPredictionTool/CryptoPredictionTool.ipynb#ch0000007?line=3'>4</a>\u001b[0m         os\u001b[39m.\u001b[39mmkdir(coin)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'c:\\\\Users\\\\WaKaBurd\\\\Documents\\\\GitHub\\\\CryptoPredictionTool\\\\search_results'"
     ]
    }
   ],
   "source": [
    "path = r'c:\\Users\\WaKaBurd\\Documents\\GitHub\\CryptoPredictionTool\\search_results'\n",
    "for coin in hourly_coins: \n",
    "        os.chdir(path)\n",
    "        os.mkdir(coin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Twitter for data on all coins supplied by dataset\n",
    "---\n",
    "Below section of code searches through twitter using keywords. Uses sift_tweet() function to remove all unnecessary characters, links, emojis & words from tweets. Also uses Textblob to append polarity column to pandas df for tracking sentiment of tweets.\n",
    "\n",
    "### What to do next:\n",
    "* Search twitter based on Cashtags & Hashtags\n",
    "* Configure Twint with Google translater so I can translate tweets from non-english langauges to english. (Need to create ticket for this in Github)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing twitter search for coin: AAVE\n",
      "searching 2022-04-17 to 2022-04-19\n",
      "[!] No more data! Scraping will stop now.\n",
      "found 0 deleted tweets in this search.\n",
      "performing twitter search for coin: AVAX\n",
      "searching 2022-04-17 to 2022-04-19\n",
      "performing twitter search for coin: BCH\n",
      "searching 2022-04-17 to 2022-04-19\n",
      "performing twitter search for coin: BTC\n",
      "searching 2022-04-17 to 2022-04-19\n",
      "performing twitter search for coin: ETH\n",
      "searching 2022-04-17 to 2022-04-19\n"
     ]
    }
   ],
   "source": [
    "# Function for iterating through coins list and storing findings in .csv files\n",
    "def search_coins(coins):\n",
    "    important_cols = ['date', 'created_at', 'tweet']\n",
    "    coin_counter = 0\n",
    "    \n",
    "    for coin in coins:\n",
    "        path = r'c:\\Users\\Brand\\OneDrive\\Documents\\GitHub\\CryptoPredictionTool\\search_results'\n",
    "        os.chdir(path)\n",
    "        #os.mkdir(coin)\n",
    "        os.chdir(coin)\n",
    "        \n",
    "        print('performing twitter search for coin:', coin)\n",
    "        \n",
    "        from_date = '2022-04-17'\n",
    "        to_date = '2022-04-19'\n",
    "        #coin = \"Bitcoin\"\n",
    "        print(f'searching {from_date} to {to_date}')\n",
    "        \n",
    "        c = twint.Config()\n",
    "        c.Limit = 3000\n",
    "        c.Lang = \"en\"\n",
    "        c.Pandas = True\n",
    "        c.Search = coin\n",
    "        c.Hide_output = True\n",
    "        c.Since = from_date\n",
    "        c.Until = to_date\n",
    "        c.Store_csv = True\n",
    "        c.Output = coin + '_' + from_date + '_' + to_date + '_search_result.csv'\n",
    "        twint.run.Search(c)\n",
    "\n",
    "\n",
    "# btc_tweets.text=btc_tweets.text.astype(str)\n",
    "# btc_tweets['Processed Tweet'] = btc_tweets['text'].apply(lambda x: sift_tweet(x.lower(), stopwords)) \n",
    "# btc_tweets['Polarity/Subjectivity'] = btc_tweets['Processed Tweet'].apply(lambda x: TextBlob(x).sentiment)            \n",
    "\n",
    "# btc_tweets\n",
    "\n",
    "search_coins(hourly_coins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below chunk is more data pre-processing. \n",
    "I need to modify the dataframe so that it contains both the price information, as well as all of the tweets so I can easily perform sentiment analysis on them using VADER.\n",
    "\n",
    "The code below will read all CSV files that were stored in both the hourly_prices directory (done earlier) as well as the tweets that are searchd for and stored in the search results folders for each currency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookin at coin number: 0\n",
      "lookin at coin number: 1\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "os.chdir(r'C:\\Users\\Brand\\OneDrive\\Documents\\GitHub\\CryptoPredictionTool\\archive')\n",
    "stopwords_file = open(\"stopwords.txt\", \"r+\")\n",
    "stopwords = list(stopwords_file.read().split('\\n'))\n",
    "\n",
    "# Need to create function for cleaning the tweets so we can derive the subjectivity and polarity using textblob.\n",
    "def sift_tweet(tweet, stop_words):\n",
    "    cleaned_tweet = tweet\n",
    "    cleaned_tweet = re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",tweet) # regex to remove all @userame, emojis, and links from tweets.\n",
    "    for word in cleaned_tweet:\n",
    "        if word in stop_words: cleaned_tweet.replace(word, '')\n",
    "    return cleaned_tweet\n",
    "\n",
    "def get_sentiment(text):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    sentiment = sia.polarity_scores(text)\n",
    "    return sentiment\n",
    "\n",
    "os.chdir(r'C:\\Users\\Brand\\OneDrive\\Documents\\GitHub\\CryptoPredictionTool\\search_results')\n",
    "tweet_pds = []\n",
    "grouped_tweets = []\n",
    "\n",
    "# Read Tweets into a DF from the CSVs\n",
    "for coin in hourly_coins:\n",
    "    \n",
    "    os.chdir(r'C:\\Users\\Brand\\OneDrive\\Documents\\GitHub\\CryptoPredictionTool\\search_results')\n",
    "    os.chdir(coin)\n",
    "    csv_names = glob.glob('*.{}'.format(extension))\n",
    "    coin_pds = []\n",
    "    for file in csv_names:\n",
    "        tweet_pd = pd.read_csv(file)\n",
    "        tweet_pd.sort_values(by='date')\n",
    "        coin_pds.append(tweet_pd)\n",
    "    tweet_pds.append(coin_pds)\n",
    "\n",
    "\n",
    "#for i in range(len(tweet_pds)):\n",
    "# This is just so i can the data i need to train a model for aave and avax. I'll do all 5 when i want to showcase something but for now i only need these 2.\n",
    "for i in range(2):\n",
    "    print('lookin at coin number:', i)\n",
    "    hourly_coin_data[i]['date'] = pd.to_datetime(hourly_coin_data[i]['date'])\n",
    "    hourly_coin_data[i]['joined_tweets'] = np.nan\n",
    "    hourly_coin_data[i]['compound'] = np.nan\n",
    "    hourly_coin_data[i]['positive'] = np.nan\n",
    "    hourly_coin_data[i]['negative'] = np.nan\n",
    "    hourly_coin_data[i]['neutral'] = np.nan\n",
    "\n",
    "    #print(hourly_coin_data[i])\n",
    "    for j in range(len(tweet_pds[i])):\n",
    "        tweet_pds[i][j]['date'] = pd.to_datetime(tweet_pds[i][j]['date'])\n",
    "\n",
    "        for day in range(1,31):\n",
    "            #print('checking day:', day)\n",
    "            for hour in range(24):\n",
    "                tweet_time_mask = (tweet_pds[i][j]['date'].dt.hour >= hour) & (tweet_pds[i][j]['date'].dt.hour < hour + 1) & \\\n",
    "                            (tweet_pds[i][j]['date'].dt.day >= day ) & (tweet_pds[i][j]['date'].dt.day < day + 1)\n",
    "                price_time_mask = (hourly_coin_data[i]['date'].dt.hour >= hour) & (hourly_coin_data[i]['date'].dt.hour < hour + 1) & \\\n",
    "                            (hourly_coin_data[i]['date'].dt.day >= day ) & (hourly_coin_data[i]['date'].dt.day < day + 1)\n",
    "\n",
    "                hour_view = tweet_pds[i][j][tweet_time_mask]\n",
    "                if hour_view.empty:\n",
    "                    continue\n",
    "                \n",
    "                hour_view['cleaned_tweet'] = hour_view['tweet'].apply(lambda x: sift_tweet(str(x).lower(), stopwords))\n",
    "\n",
    "                joined_tweets = ' '.join(hour_view['tweet'])\n",
    "                joined_clean_tweets = ' '.join(hour_view['cleaned_tweet'])\n",
    "\n",
    "                SIA = get_sentiment(joined_tweets)\n",
    "                compound = SIA['compound']                    # Score representing sum(lexicon ratings)\n",
    "                pos = SIA['pos']\n",
    "                neg = SIA['neg']\n",
    "                neu = SIA['neu']\n",
    "\n",
    "                index = hourly_coin_data[i][price_time_mask].index\n",
    "                for ind in index:\n",
    "                    hourly_coin_data[i].at[ind,'joined_tweets'] = joined_tweets\n",
    "                    hourly_coin_data[i].at[ind,'polarity'] = TextBlob(joined_clean_tweets).sentiment[0]            # Lambda function for creating Polarity value in Coin Dataframe using Textblob\n",
    "                    hourly_coin_data[i].at[ind,'subjectivity'] = TextBlob(joined_clean_tweets).sentiment[1]            # Lambda function for creating Polarity value in Coin Dataframe using Textblob\n",
    "                    hourly_coin_data[i].at[ind,'compound'] = compound\n",
    "                    hourly_coin_data[i].at[ind,'positive'] = pos\n",
    "                    hourly_coin_data[i].at[ind,'negative'] = neg\n",
    "                    hourly_coin_data[i].at[ind,'neutral'] = neu\n",
    "                \n",
    "                #Processing twitter live tweets\n",
    "\n",
    "\n",
    "                # hourly_coin_data[i]['Polarity'] = hourly_coin_data[i]['Processed Tweet'].apply(lambda x: TextBlob(x).sentiment[0])            # Lambda function for creating Polarity value in Coin Dataframe using Textblob\n",
    "                # hourly_coin_data[i]['Subjectivity'] = hourly_coin_data[i]['Processed Tweet'].apply(lambda x: TextBlob(x).sentiment[1])            # Lambda function for creating Polarity value in Coin Dataframe using Textblob\n",
    "\n",
    "                \n",
    "\n",
    "    hourly_coin_data[i] = hourly_coin_data[i][hourly_coin_data[i]['joined_tweets'].notna()]     # Drop all NAN rows (rows we don't have tweets for)\n",
    "\n",
    "print(len(tweet_pds[0]))\n",
    "#pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appending a label to each row signifying an increase/decrease in price during that hour. \n",
    "\n",
    "If the price increases/no change we append a 1 to the price change column for that row, if it decreases we append a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(hourly_coin_data)):\n",
    "    hourly_coin_data[i].reset_index()\n",
    "    hourly_coin_data[i]['price_change'] = np.nan\n",
    "    for index, row in hourly_coin_data[i].iterrows():\n",
    "        if row.open > row.close:\n",
    "            hourly_coin_data[i].at[index, 'price_change'] = 0\n",
    "        else:\n",
    "            hourly_coin_data[i].at[index, 'price_change'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unix</th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>Volume AVAX</th>\n",
       "      <th>Volume USD</th>\n",
       "      <th>joined_tweets</th>\n",
       "      <th>compound</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>price_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1649808000</td>\n",
       "      <td>2022-04-13 00:00:00</td>\n",
       "      <td>AVAX/USD</td>\n",
       "      <td>76.44000</td>\n",
       "      <td>77.07000</td>\n",
       "      <td>76.44000</td>\n",
       "      <td>77.07000</td>\n",
       "      <td>57.676665</td>\n",
       "      <td>4445.140558</td>\n",
       "      <td>@0xOmniGod minted out on avax! that's the issu...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.212326</td>\n",
       "      <td>0.511532</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1649779200</td>\n",
       "      <td>2022-04-12 16:00:00</td>\n",
       "      <td>AVAX/USD</td>\n",
       "      <td>76.60617</td>\n",
       "      <td>76.60617</td>\n",
       "      <td>76.60617</td>\n",
       "      <td>76.60617</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>@calmanmuratali Avax üö®üö®BREAKING NEWSüö®üö®  üßä Whit...</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.141817</td>\n",
       "      <td>0.469212</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1649775600</td>\n",
       "      <td>2022-04-12 15:00:00</td>\n",
       "      <td>AVAX/USD</td>\n",
       "      <td>76.32321</td>\n",
       "      <td>77.00999</td>\n",
       "      <td>76.10002</td>\n",
       "      <td>76.60617</td>\n",
       "      <td>193.335412</td>\n",
       "      <td>14810.685433</td>\n",
       "      <td>@CryptoBoy55555 $AVOGE and $AVAINU next meme c...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.179057</td>\n",
       "      <td>0.525056</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1649772000</td>\n",
       "      <td>2022-04-12 14:00:00</td>\n",
       "      <td>AVAX/USD</td>\n",
       "      <td>78.25434</td>\n",
       "      <td>78.25434</td>\n",
       "      <td>75.80626</td>\n",
       "      <td>76.10000</td>\n",
       "      <td>766.725529</td>\n",
       "      <td>58347.812780</td>\n",
       "      <td>@Avax_News @avalancheavax @PlayCrabada @Financ...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.206693</td>\n",
       "      <td>0.510654</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1649768400</td>\n",
       "      <td>2022-04-12 13:00:00</td>\n",
       "      <td>AVAX/USD</td>\n",
       "      <td>79.33458</td>\n",
       "      <td>79.35680</td>\n",
       "      <td>78.63002</td>\n",
       "      <td>78.70000</td>\n",
       "      <td>90.607519</td>\n",
       "      <td>7130.811722</td>\n",
       "      <td>#BTC hitting a double bottom here but many man...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.177450</td>\n",
       "      <td>0.520809</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1649764800</td>\n",
       "      <td>2022-04-12 12:00:00</td>\n",
       "      <td>AVAX/USD</td>\n",
       "      <td>77.67999</td>\n",
       "      <td>79.00000</td>\n",
       "      <td>77.67999</td>\n",
       "      <td>79.00000</td>\n",
       "      <td>202.484185</td>\n",
       "      <td>15996.250629</td>\n",
       "      <td>@Leopoldinhooo @HeroesOnAvax @haydenandoe  @an...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.168016</td>\n",
       "      <td>0.528426</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1649761200</td>\n",
       "      <td>2022-04-12 11:00:00</td>\n",
       "      <td>AVAX/USD</td>\n",
       "      <td>78.07534</td>\n",
       "      <td>78.61000</td>\n",
       "      <td>77.98094</td>\n",
       "      <td>78.61000</td>\n",
       "      <td>112.599674</td>\n",
       "      <td>8851.460409</td>\n",
       "      <td>@AvaxFrogsFPC Let's go! üî∫Ô∏èüê∏  @genesisvalles  @...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.205873</td>\n",
       "      <td>0.502809</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1649757600</td>\n",
       "      <td>2022-04-12 10:00:00</td>\n",
       "      <td>AVAX/USD</td>\n",
       "      <td>77.62999</td>\n",
       "      <td>77.62999</td>\n",
       "      <td>77.62999</td>\n",
       "      <td>77.62999</td>\n",
       "      <td>77.158865</td>\n",
       "      <td>5989.841912</td>\n",
       "      <td>‚úÖ ETH Giveaway!  üöÄ Giving away 0.2 ETH (~$606)...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.219346</td>\n",
       "      <td>0.512423</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1649754000</td>\n",
       "      <td>2022-04-12 09:00:00</td>\n",
       "      <td>AVAX/USD</td>\n",
       "      <td>76.94712</td>\n",
       "      <td>77.27140</td>\n",
       "      <td>76.88680</td>\n",
       "      <td>77.25000</td>\n",
       "      <td>2341.778340</td>\n",
       "      <td>180902.376741</td>\n",
       "      <td>500 #avax replies and I‚Äôll get the ‚ÄúAVALANCHE‚Äù...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.170048</td>\n",
       "      <td>0.513387</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1649750400</td>\n",
       "      <td>2022-04-12 08:00:00</td>\n",
       "      <td>AVAX/USD</td>\n",
       "      <td>77.26954</td>\n",
       "      <td>77.61999</td>\n",
       "      <td>77.26954</td>\n",
       "      <td>77.28688</td>\n",
       "      <td>980.104262</td>\n",
       "      <td>75749.200494</td>\n",
       "      <td>@JirkaSaFuCalls Let‚Äôs goooo #avoge #avax top a...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.166212</td>\n",
       "      <td>0.477566</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1649548800</td>\n",
       "      <td>2022-04-10 00:00:00</td>\n",
       "      <td>AVAX/USD</td>\n",
       "      <td>84.50998</td>\n",
       "      <td>84.81999</td>\n",
       "      <td>84.50998</td>\n",
       "      <td>84.81999</td>\n",
       "      <td>5.161774</td>\n",
       "      <td>437.821621</td>\n",
       "      <td>@Binance_Turkish Avax #AVAXUSDT Bear Alert!  5...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.169873</td>\n",
       "      <td>0.514901</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1649433600</td>\n",
       "      <td>2022-04-08 16:00:00</td>\n",
       "      <td>AVAX/USD</td>\n",
       "      <td>90.00000</td>\n",
       "      <td>90.50000</td>\n",
       "      <td>88.55000</td>\n",
       "      <td>88.94340</td>\n",
       "      <td>118.948023</td>\n",
       "      <td>10579.641569</td>\n",
       "      <td>‚Üë #HCT PRICE = 0,008787 Rank = #2,302 #AVAX = ...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.151020</td>\n",
       "      <td>0.537122</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1649430000</td>\n",
       "      <td>2022-04-08 15:00:00</td>\n",
       "      <td>AVAX/USD</td>\n",
       "      <td>89.60000</td>\n",
       "      <td>89.87204</td>\n",
       "      <td>89.24727</td>\n",
       "      <td>89.62213</td>\n",
       "      <td>48.754425</td>\n",
       "      <td>4369.475428</td>\n",
       "      <td>@0xKichtaPurple Merci d'organiser ce concours ...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.176888</td>\n",
       "      <td>0.550035</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1649426400</td>\n",
       "      <td>2022-04-08 14:00:00</td>\n",
       "      <td>AVAX/USD</td>\n",
       "      <td>86.83571</td>\n",
       "      <td>89.81000</td>\n",
       "      <td>86.83571</td>\n",
       "      <td>89.57985</td>\n",
       "      <td>204.622114</td>\n",
       "      <td>18330.018289</td>\n",
       "      <td>@CImbulagoda @Solana_Classic @PancakeSwap It c...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.175503</td>\n",
       "      <td>0.501092</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>1649422800</td>\n",
       "      <td>2022-04-08 13:00:00</td>\n",
       "      <td>AVAX/USD</td>\n",
       "      <td>86.56721</td>\n",
       "      <td>86.86000</td>\n",
       "      <td>85.24979</td>\n",
       "      <td>86.42999</td>\n",
       "      <td>120.037288</td>\n",
       "      <td>10374.821643</td>\n",
       "      <td>#EverRise  $0.001012 Œî +0.6% üü¢ $72.4M Market C...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.178868</td>\n",
       "      <td>0.526139</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           unix                date    symbol      open      high       low  \\\n",
       "48   1649808000 2022-04-13 00:00:00  AVAX/USD  76.44000  77.07000  76.44000   \n",
       "56   1649779200 2022-04-12 16:00:00  AVAX/USD  76.60617  76.60617  76.60617   \n",
       "57   1649775600 2022-04-12 15:00:00  AVAX/USD  76.32321  77.00999  76.10002   \n",
       "58   1649772000 2022-04-12 14:00:00  AVAX/USD  78.25434  78.25434  75.80626   \n",
       "59   1649768400 2022-04-12 13:00:00  AVAX/USD  79.33458  79.35680  78.63002   \n",
       "60   1649764800 2022-04-12 12:00:00  AVAX/USD  77.67999  79.00000  77.67999   \n",
       "61   1649761200 2022-04-12 11:00:00  AVAX/USD  78.07534  78.61000  77.98094   \n",
       "62   1649757600 2022-04-12 10:00:00  AVAX/USD  77.62999  77.62999  77.62999   \n",
       "63   1649754000 2022-04-12 09:00:00  AVAX/USD  76.94712  77.27140  76.88680   \n",
       "64   1649750400 2022-04-12 08:00:00  AVAX/USD  77.26954  77.61999  77.26954   \n",
       "120  1649548800 2022-04-10 00:00:00  AVAX/USD  84.50998  84.81999  84.50998   \n",
       "152  1649433600 2022-04-08 16:00:00  AVAX/USD  90.00000  90.50000  88.55000   \n",
       "153  1649430000 2022-04-08 15:00:00  AVAX/USD  89.60000  89.87204  89.24727   \n",
       "154  1649426400 2022-04-08 14:00:00  AVAX/USD  86.83571  89.81000  86.83571   \n",
       "155  1649422800 2022-04-08 13:00:00  AVAX/USD  86.56721  86.86000  85.24979   \n",
       "\n",
       "        close  Volume AVAX     Volume USD  \\\n",
       "48   77.07000    57.676665    4445.140558   \n",
       "56   76.60617     0.000000       0.000000   \n",
       "57   76.60617   193.335412   14810.685433   \n",
       "58   76.10000   766.725529   58347.812780   \n",
       "59   78.70000    90.607519    7130.811722   \n",
       "60   79.00000   202.484185   15996.250629   \n",
       "61   78.61000   112.599674    8851.460409   \n",
       "62   77.62999    77.158865    5989.841912   \n",
       "63   77.25000  2341.778340  180902.376741   \n",
       "64   77.28688   980.104262   75749.200494   \n",
       "120  84.81999     5.161774     437.821621   \n",
       "152  88.94340   118.948023   10579.641569   \n",
       "153  89.62213    48.754425    4369.475428   \n",
       "154  89.57985   204.622114   18330.018289   \n",
       "155  86.42999   120.037288   10374.821643   \n",
       "\n",
       "                                         joined_tweets  compound  positive  \\\n",
       "48   @0xOmniGod minted out on avax! that's the issu...    1.0000     0.124   \n",
       "56   @calmanmuratali Avax üö®üö®BREAKING NEWSüö®üö®  üßä Whit...    0.9999     0.096   \n",
       "57   @CryptoBoy55555 $AVOGE and $AVAINU next meme c...    1.0000     0.113   \n",
       "58   @Avax_News @avalancheavax @PlayCrabada @Financ...    1.0000     0.113   \n",
       "59   #BTC hitting a double bottom here but many man...    1.0000     0.123   \n",
       "60   @Leopoldinhooo @HeroesOnAvax @haydenandoe  @an...    1.0000     0.106   \n",
       "61   @AvaxFrogsFPC Let's go! üî∫Ô∏èüê∏  @genesisvalles  @...    1.0000     0.116   \n",
       "62   ‚úÖ ETH Giveaway!  üöÄ Giving away 0.2 ETH (~$606)...    1.0000     0.128   \n",
       "63   500 #avax replies and I‚Äôll get the ‚ÄúAVALANCHE‚Äù...    1.0000     0.100   \n",
       "64   @JirkaSaFuCalls Let‚Äôs goooo #avoge #avax top a...    1.0000     0.103   \n",
       "120  @Binance_Turkish Avax #AVAXUSDT Bear Alert!  5...    1.0000     0.107   \n",
       "152  ‚Üë #HCT PRICE = 0,008787 Rank = #2,302 #AVAX = ...    1.0000     0.107   \n",
       "153  @0xKichtaPurple Merci d'organiser ce concours ...    1.0000     0.116   \n",
       "154  @CImbulagoda @Solana_Classic @PancakeSwap It c...    1.0000     0.117   \n",
       "155  #EverRise  $0.001012 Œî +0.6% üü¢ $72.4M Market C...    1.0000     0.135   \n",
       "\n",
       "     negative  neutral  polarity  subjectivity  price_change  \n",
       "48      0.036    0.840  0.212326      0.511532           1.0  \n",
       "56      0.033    0.871  0.141817      0.469212           1.0  \n",
       "57      0.037    0.849  0.179057      0.525056           1.0  \n",
       "58      0.034    0.853  0.206693      0.510654           0.0  \n",
       "59      0.037    0.839  0.177450      0.520809           0.0  \n",
       "60      0.032    0.862  0.168016      0.528426           1.0  \n",
       "61      0.039    0.845  0.205873      0.502809           1.0  \n",
       "62      0.036    0.836  0.219346      0.512423           1.0  \n",
       "63      0.026    0.874  0.170048      0.513387           1.0  \n",
       "64      0.029    0.867  0.166212      0.477566           1.0  \n",
       "120     0.034    0.860  0.169873      0.514901           1.0  \n",
       "152     0.030    0.863  0.151020      0.537122           0.0  \n",
       "153     0.025    0.859  0.176888      0.550035           1.0  \n",
       "154     0.026    0.857  0.175503      0.501092           1.0  \n",
       "155     0.029    0.836  0.178868      0.526139           0.0  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_coin_data[1].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Train Neural Net on Dataset (Attempt 1)\n",
    "---\n",
    "\n",
    "\n",
    "### What to do next:\n",
    "* Probably attempt it differently. Outcomes are horrid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proper Implementation: LDA With Sentiment Analysis\n",
    "---\n",
    "Yeah the last one wasn't good. This one is ight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.56      0.67         9\n",
      "         1.0       0.50      0.80      0.62         5\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.67      0.68      0.64        14\n",
      "weighted avg       0.71      0.64      0.65        14\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.75         4\n",
      "   macro avg       0.50      0.38      0.43         4\n",
      "weighted avg       1.00      0.75      0.86         4\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         8\n",
      "         1.0       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67         1\n",
      "         1.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         1\n",
      "   macro avg       1.00      1.00      1.00         1\n",
      "weighted avg       1.00      1.00      1.00         1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# These are all the columns we actually want to keep for the purposes of training & using the model.\n",
    "model_cols = ['open', 'high', 'low', 'Volume USD', 'compound', 'positive', 'negative', 'neutral', 'polarity', 'subjectivity', 'price_change']\n",
    "os.chdir(r'C:\\Users\\Brand\\OneDrive\\Documents\\GitHub\\CryptoPredictionTool\\hourly_coin_data')\n",
    "\n",
    "for i in range(len(hourly_coin_data)):\n",
    "\n",
    "    model_df = hourly_coin_data[i][model_cols]\n",
    "    model_df.to_csv(f'model_df_{i}.csv')\n",
    "\n",
    "    # Feature Dataset\n",
    "    x = model_df\n",
    "    x.drop(['price_change'], axis=1)\n",
    "    np.asarray(x)\n",
    "\n",
    "    # Target Dataset\n",
    "    y = np.array(model_df['price_change'])\n",
    "\n",
    "    # split into test & train\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    # Create svm model\n",
    "    model = LinearDiscriminantAnalysis().fit(x_train, y_train)\n",
    "    predictions = model.predict(x_test)\n",
    "    print(classification_report(y_test, predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull data from the last hour to make prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_request(url, headers, params, next_token=None):\n",
    "    params['next_token'] = next_token\n",
    "    response = requests.request('GET', url, headers=headers, params=params)\n",
    "    print('Endpoint response code:' + str(response.status_code))\n",
    "    if (response.status_code != 200):\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "def pull_live_tweets(coin):\n",
    "\n",
    "    # Pull tweets from the last hour\n",
    "    path = r'c:\\Users\\Brand\\OneDrive\\Documents\\GitHub\\CryptoPredictionTool\\predicted_trends'\n",
    "    os.chdir(path)\n",
    "    #os.chdir(coin)\n",
    "\n",
    "    print('performing twitter search for coin:', coin)\n",
    "\n",
    "    # 1 hour ago\n",
    "    from_date = datetime.now(timezone.utc) - timedelta(hours = 1)\n",
    "    to_date = datetime.now(timezone.utc) + timedelta(seconds=-30)\n",
    "    \n",
    "    iso_from_date = from_date.isoformat()\n",
    "    iso_to_date = to_date.isoformat()\n",
    "\n",
    "    from_date = from_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    to_date = to_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    print(f'searching {from_date} to {to_date}')\n",
    "    \n",
    "    bearer_token = 'AAAAAAAAAAAAAAAAAAAAAJwBbgEAAAAAyi3tWb4jDN72EZqz6dcWgOIizuc%3DsC3xrWGrxPCwiKwqy2fINUgJDs2qKaZNlITIIy75Pss1oiMeTN'\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": \"Bearer {}\".format(bearer_token)\n",
    "    }\n",
    "\n",
    "    url = 'https://api.twitter.com/2/tweets/search/recent'\n",
    "\n",
    "    params = {\n",
    "        'query': coin,\n",
    "        'start_time': iso_from_date,\n",
    "        'end_time': iso_to_date,\n",
    "        'max_results': 10,\n",
    "        'next_token':{}\n",
    "    }\n",
    "\n",
    "    json_response = send_request(url, headers, params)\n",
    "    print(json.dumps(json_response, indent=4, sort_keys=True))\n",
    "    return json_response\n",
    "    # Run Textblob on tweets\n",
    "\n",
    "    # Analyze sentiment of tweets\n",
    "\n",
    "    # Merge datasets\n",
    "\n",
    "    # Feed them into model\n",
    "\n",
    "# Pull tweets on topic from last 30 minutes\n",
    "fetched_tweets = pull_live_tweets('AVAX lang:en')\n",
    "fetched_tweets_df = pd.DataFrame(fetched_tweets['data'])\n",
    "fetched_tweets_df.to_csv('recently_fetched_tweets.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull financial data from yahoo finance for the current hour\n",
    "# Have to use Alphavantage api\n",
    "\n",
    "av_api_key = 'GD982KLZ6PZ69GQ0'\n",
    "path = r'c:\\Users\\Brand\\OneDrive\\Documents\\GitHub\\CryptoPredictionTool\\prices\\LivePrices'\n",
    "os.chdir(path)\n",
    "\n",
    "\n",
    "def get_prices(coin):\n",
    "    url = f'https://www.alphavantage.co/query?function=CRYPTO_INTRADAY&symbol={coin}&market=USD&interval=1min&apikey={av_api_key}&datatype=csv'\n",
    "    req = requests.get(url)\n",
    "    data = req.content\n",
    "    csv_file = open(f'{coin}_prices.csv','wb')\n",
    "    csv_file.write(data)\n",
    "    csv_file.close()\n",
    "    return\n",
    "\n",
    "get_prices('AVAX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26429"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "live_prices = pd.read_csv('AVAX_prices.csv')    # read in live prices csv\n",
    "kept_prices = live_prices.head(60)              # keep only the last 60 minutes.\n",
    "max_val = kept_prices['high'].max(axis=0)       # Find the max value in the last 60 minutes\n",
    "low_val = kept_prices['low'].min(axis=0)        # find the lowesst value in the last 60 minutes\n",
    "open_val = kept_prices.tail(1)                  # Price from 60 minutes ago. (opening price of the last hour) \n",
    "volume = kept_prices['volume'].sum(axis=0)      # summate the total volume traded from the last hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run textblob on tweets for polarity & subjectivity\n",
    "fetched_tweets."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b4c0bf06c6142ddc920bc4833060833a5c39c864bf9bfacfcb217d05e37f17a2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
